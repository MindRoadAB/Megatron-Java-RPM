# Global config file for Megatron (dev).
#
# Note: A global property may be overridden by a job-type propery.
# Job-type properties are defined in the job-type directory, one file
# for each job-type, e.g. "shadowserver-ddos.properties". 


##
# General
##

# Filename for log4j config-file.
general.log4jConfigFile=/etc/megatron/log4j.properties

# Directory for log files (must correspond to directory in log4j.properties).
general.logDir=/var/megatron/log

# Directory for job-type properties files.
general.jobTypeConfigDir=/etc/megatron/job-type

# Slurp directory. Input files in this directory will be processed automagically. 
general.slurpDir=/var/megatron/slurp

# Output directory for export files. May be overridden by "--output-dir". 
general.outputDir=/var/megatron/tmp/export

# Directory for temporary files.
general.tmpDir=/var/megatron/tmp/work

# Character-set for log files, e.g. "ISO-8859-1", "UTF-8".
general.inputCharSet=UTF-8

# Map a filename to a job-type. Files dropped in the slurp directory must have
# a mapping in this list. Format: <reg-exp to match filename>=job-type 
# Example: 2009-06-08-drone-report-se.log --> shadowserver-drone
general.filenameMapperList.0=^\d{4}+-\d\d-\d\d-scan_ntp-sweden-geo.csv=scan_ntp-sweden-geo
general.filenameMapperList.1=^\d{4}+-\d\d-\d\d-scan_ubiquiti-sweden-geo.csv=scan_ubiquiti-sweden-geo
general.filenameMapperList.2=^\d{4}+-\d\d-\d\d-scan_coap-sweden-geo.csv=scan_coap-sweden-geo
general.filenameMapperList.3=^\d{4}+-\d\d-\d\d-scan_ipmi-sweden-geo.csv=scan_ipmi-sweden-geo
general.filenameMapperList.4=^\d{4}+-\d\d-\d\d-scan_ldap_tcp-se-tld-rhost.csv=scan_ldap_tcp-se-tld-rhost
general.filenameMapperList.5=^\d{4}+-\d\d-\d\d-scan_tftp-sweden-geo.csv=scan_tftp-sweden-geo
general.filenameMapperList.6=^\d{4}+-\d\d-\d\d-scan_ipp-se-tld-rhost.csv=scan_ipp-se-tld-rhost
general.filenameMapperList.7=^\d{4}+-\d\d-\d\d-event4_sinkhole_http_referer-sweden-geo.csv=event4_sinkhole_http_referer-sweden-geo
general.filenameMapperList.8=^\d{4}+-\d\d-\d\d-event4_honeypot_ddos_amp-se-tld-rhost.csv=event4_honeypot_ddos_amp-se-tld-rhost
general.filenameMapperList.9=^\d{4}+-\d\d-\d\d-scan_ldap-sweden-geo.csv=scan_ldap-sweden-geo
general.filenameMapperList.10=^\d{4}+-\d\d-\d\d-scan_vnc-sweden-geo.csv=scan_vnc-sweden-geo
general.filenameMapperList.11=^\d{4}+-\d\d-\d\d-event6_sinkhole_http-sweden-geo.csv=event6_sinkhole_http-sweden-geo
general.filenameMapperList.12=^\d{4}+-\d\d-\d\d-scan6_http_vulnerable-sweden-geo.csv=scan6_http_vulnerable-sweden-geo
general.filenameMapperList.13=^\d{4}+-\d\d-\d\d-scan_xdmcp-sweden-geo.csv=scan_xdmcp-sweden-geo
general.filenameMapperList.14=^\d{4}+-\d\d-\d\d-scan6_smtp_vulnerable-sweden-geo.csv=scan6_smtp_vulnerable-sweden-geo
general.filenameMapperList.15=^\d{4}+-\d\d-\d\d-event4_honeypot_brute_force-sweden-geo.csv=event4_honeypot_brute_force-sweden-geo
general.filenameMapperList.16=^\d{4}+-\d\d-\d\d-scan_isakmp-sweden-geo.csv=scan_isakmp-sweden-geo
general.filenameMapperList.17=^\d{4}+-\d\d-\d\d-scan_nat_pmp-sweden-geo.csv=scan_nat_pmp-sweden-geo
general.filenameMapperList.18=^\d{4}+-\d\d-\d\d-event4_sinkhole_http-sweden-geo.csv=event4_sinkhole_http-sweden-geo
general.filenameMapperList.19=^\d{4}+-\d\d-\d\d-cisco_smart_install-sweden-geo.csv=cisco_smart_install-sweden-geo
general.filenameMapperList.20=^\d{4}+-\d\d-\d\d-scan_redis-sweden-geo.csv=scan_redis-sweden-geo
general.filenameMapperList.21=^\d{4}+-\d\d-\d\d-event4_honeypot_ddos_amp-sweden-geo.csv=event4_honeypot_ddos_amp-sweden-geo
general.filenameMapperList.22=^\d{4}+-\d\d-\d\d-blocklist-sweden-geo.csv=blocklist-sweden-geo
general.filenameMapperList.23=^\d{4}+-\d\d-\d\d-scan_snmp-sweden-geo.csv=scan_snmp-sweden-geo
general.filenameMapperList.24=^\d{4}+-\d\d-\d\d-scan_telnet-sweden-geo.csv=scan_telnet-sweden-geo
general.filenameMapperList.25=^\d{4}+-\d\d-\d\d-scan_ldap_tcp-sweden-geo.csv=scan_ldap_tcp-sweden-geo
general.filenameMapperList.26=^\d{4}+-\d\d-\d\d-scan_ntpmonitor-sweden-geo.csv=scan_ntpmonitor-sweden-geo
general.filenameMapperList.27=^\d{4}+-\d\d-\d\d-device_id6-sweden-geo.csv=device_id6-sweden-geo
general.filenameMapperList.28=^\d{4}+-\d\d-\d\d-compromised_website-sweden-geo.csv=compromised_website-sweden-geo
general.filenameMapperList.29=^\d{4}+-\d\d-\d\d-event4_microsoft_sinkhole_http-sweden-geo.csv=event4_microsoft_sinkhole_http-sweden-geo
general.filenameMapperList.30=^\d{4}+-\d\d-\d\d-scan_afp-se-tld-rhost.csv=scan_afp-se-tld-rhost
general.filenameMapperList.31=^\d{4}+-\d\d-\d\d-scan_rsync-se-tld-rhost.csv=scan_rsync-se-tld-rhost
general.filenameMapperList.32=^\d{4}+-\d\d-\d\d-scan6_ssl_poodle-sweden-geo.csv=scan6_ssl_poodle-sweden-geo
general.filenameMapperList.33=^\d{4}+-\d\d-\d\d-scan_mssql-sweden-geo.csv=scan_mssql-sweden-geo
general.filenameMapperList.34=^\d{4}+-\d\d-\d\d-scan_ssl_freak-sweden-geo.csv=scan_ssl_freak-sweden-geo
general.filenameMapperList.35=^\d{4}+-\d\d-\d\d-scan_ubiquiti-se-tld-rhost.csv=scan_ubiquiti-se-tld-rhost
general.filenameMapperList.36=^\d{4}+-\d\d-\d\d-scan_rsync-sweden-geo.csv=scan_rsync-sweden-geo
general.filenameMapperList.37=^\d{4}+-\d\d-\d\d-scan_mqtt-sweden-geo.csv=scan_mqtt-sweden-geo
general.filenameMapperList.38=^\d{4}+-\d\d-\d\d-scan_smtp_vulnerable-sweden-geo.csv=scan_smtp_vulnerable-sweden-geo
general.filenameMapperList.39=^\d{4}+-\d\d-\d\d-scan_ard-sweden-geo.csv=scan_ard-sweden-geo
general.filenameMapperList.40=^\d{4}+-\d\d-\d\d-scan_radmin-sweden-geo.csv=scan_radmin-sweden-geo
general.filenameMapperList.41=^\d{4}+-\d\d-\d\d-scan_chargen-sweden-geo.csv=scan_chargen-sweden-geo
general.filenameMapperList.42=^\d{4}+-\d\d-\d\d-scan_http_vulnerable-sweden-geo.csv=scan_http_vulnerable-sweden-geo
general.filenameMapperList.43=^\d{4}+-\d\d-\d\d-event4_microsoft_sinkhole-sweden-geo.csv=event4_microsoft_sinkhole-sweden-geo
general.filenameMapperList.44=^\d{4}+-\d\d-\d\d-scan_db2-sweden-geo.csv=scan_db2-sweden-geo
general.filenameMapperList.45=^\d{4}+-\d\d-\d\d-scan_qotd-sweden-geo.csv=scan_qotd-sweden-geo
general.filenameMapperList.46=^\d{4}+-\d\d-\d\d-scan_amqp-sweden-geo.csv=scan_amqp-sweden-geo
general.filenameMapperList.47=^\d{4}+-\d\d-\d\d-scan_exchange-sweden-geo.csv=scan_exchange-sweden-geo
general.filenameMapperList.48=^\d{4}+-\d\d-\d\d-scan_ipp-sweden-geo.csv=scan_ipp-sweden-geo
general.filenameMapperList.49=^\d{4}+-\d\d-\d\d-scan_mongodb-sweden-geo.csv=scan_mongodb-sweden-geo
general.filenameMapperList.50=^\d{4}+-\d\d-\d\d-scan_memcached-sweden-geo.csv=scan_memcached-sweden-geo
general.filenameMapperList.51=^\d{4}+-\d\d-\d\d-scan6_telnet-sweden-geo.csv=scan6_telnet-sweden-geo
general.filenameMapperList.52=^\d{4}+-\d\d-\d\d-scan_adb-sweden-geo.csv=scan_adb-sweden-geo
general.filenameMapperList.53=^\d{4}+-\d\d-\d\d-scan_elasticsearch-sweden-geo.csv=scan_elasticsearch-sweden-geo
general.filenameMapperList.54=^\d{4}+-\d\d-\d\d-event4_sinkhole-sweden-geo.csv=event4_sinkhole-sweden-geo
general.filenameMapperList.55=^\d{4}+-\d\d-\d\d-event4_honeypot_http_scan-sweden-geo.csv=event4_honeypot_http_scan-sweden-geo
general.filenameMapperList.56=^\d{4}+-\d\d-\d\d-scan_netbios-sweden-geo.csv=scan_netbios-sweden-geo
general.filenameMapperList.57=^\d{4}+-\d\d-\d\d-scan_smb-sweden-geo.csv=scan_smb-sweden-geo
general.filenameMapperList.58=^\d{4}+-\d\d-\d\d-scan_adb-se-tld-rhost.csv=scan_adb-se-tld-rhost
general.filenameMapperList.59=^\d{4}+-\d\d-\d\d-scan_afp-sweden-geo.csv=scan_afp-sweden-geo
general.filenameMapperList.60=^\d{4}+-\d\d-\d\d-scan_mdns-sweden-geo.csv=scan_mdns-sweden-geo
general.filenameMapperList.61=^\d{4}+-\d\d-\d\d-scan_dns-sweden-geo.csv=scan_dns-sweden-geo
general.filenameMapperList.62=^\d{4}+-\d\d-\d\d-scan_rdpeudp-sweden-geo.csv=scan_rdpeudp-sweden-geo
general.filenameMapperList.63=^\d{4}+-\d\d-\d\d-event4_honeypot_darknet-sweden-geo.csv=event4_honeypot_darknet-sweden-geo



# Whois server. Used for example by --update-netname (NetnameUpdater).
general.whoisServer=whois.ripe.net

# Priority equals or above this threshold is considered "high priority".
# A notification email may be sent if high priority entries exists in a job. 
general.highPriorityNotification.threshold=40

# Issue warning if one timestamp in the input file is older than this max age (given in seconds).
# Use -1 to turn off warning. 1 week=7*24*60*60=604800
general.timestampWarning.maxAge=604800

# Print progress to console using this specified interval (given in seconds).
general.printProgressInterval=15

# What to do if file already processed (MD5-hash exists in db)?
# Values: error|skip|rerun
general.fileAlreadyProcessedAction=error


##
# GeoIP
##

# Filename for the GeoIP Country database.
geoIp.countryDatabaseFile=/etc/megatron/geoip-db/GeoIP.dat

# Filename for the GeoIP ASN database.
geoIp.asnDatabaseFile=/etc/megatron/geoip-db/GeoIPASNum.dat

# Filename for the GeoIP City database (contains latitude/longitude, country, city etc.).
geoIp.cityDatabaseFile=/etc/megatron/geoip-db/GeoLiteCity.dat

# If true, uses the city database instead of the country database.
# Set to true if the commercial city database is used.
geoIp.useCityDatabaseForCountryLookups=false


##
# dnsjava
##

# Use dnsjava class library? dnsjava have much better performance than the standard JDK implementation.  
dnsJava.useDnsJava=true

# If true, SimpleResolver will be used which will use only one DNS server.
# If false, ExtendedResolver will be used which uses multiple DNS servers.
# SimpleResolver is of course faster, but less reliable. 
dnsJava.useSimpleResolver=true

# Comma separated list of DNS servers. If undefined, the machine's default DNS
# servers will be used (as defined in e.g. /etc/resolv.conf).
#dnsJava.dnsServers=8.8.4.4,8.8.8.8

# Amount of seconds to wait for a response before giving up.
dnsJava.timeOut=2


##
# Database
##

# Note: Remember to change "hibernate.cfg.xml" if anything in this section is modified.

db.username=megatron
db.password=megatron

# local
db.name=megatron
db.server=megatron-db-host
db.port=3306

db.jdbc.url=jdbc:mysql://{db.server}:{db.port}/{db.name}
db.jdbc.driverClassName=com.mysql.jdbc.Driver


##
# System Data Import
##

# File that contains the system definitions and contact data
import.dataFile=/etc/megatron/dev/systemdata.txt


##
# BGP Table Import
##

# File that contains the BGP table dump.
bgp.importFile=test-data-bronto/bgp-table-full.txt

# Name-Value list (BGP prefix-ASN) with prefixes that are missing in the BGP table. 
# TODO Change on install 
# Sitic AS41884
bgp.hardCodedPrefixes.0=192.121.218.0/24=41884


##
# Export
##

# Directory for export templates.
export.templateDir=/etc/megatron/template/export

# Filename to file templates. "headerFile" and "footerFile" may be undefined, but
# "rowFile" is mandatory. The directory is specified in "export.templateDir".
#export.headerFile=
export.rowFile=debug_row.txt
#export.footerFile=

# Character-set for export files, e.g. "ISO-8859-1", "UTF-8".
export.charSet=UTF-8

# Date-and time format in export. Will also be used in mail templates.
# Format reference: http://java.sun.com/j2se/1.5.0/docs/api/java/text/SimpleDateFormat.html
# Example: yyyy-MM-dd HH:mm:ss z --> 2009-07-02 11:39:41 UTC, dd/MMM/yyyy:HH:mm:ss Z --> 07/Jul/2009:11:04:34 +0000
export.timestampFormat=yyyy-MM-dd HH:mm:ss z

# List of attribute value rewriters, e.g. rewrites the url from "http" to "hxxp".
# Attribute values are rewritten just before they are added to the template.    
# 
# Syntax: <attribute name>:<from>--><replace with> 
# Note 1: Spaces are not trimmed from property above.
# Note 2: Both file- and mail export are affected by this property. 
#
# See also "parser.rewriters" (will store rewrites in db)
# 
# This example rewrites URLs from "http" to "hxxp" and mask IP addresses:  
#export.rewriters.0=url:(?i)(h)tt(ps{0,1}://.+)-->$1xx$2
#export.rewriters.1=ipAddress:(\d{1,3})\.(\d{1,3})\.\d{1,3}\.\d{1,3}-->$1.$2.x.x

# Converts job-type names (format: from=to). Use this property when an internal
# name should not be known public. Job-type names can be used in attachment. 
# Example:
#export.jobTypeNameMapper.0=nda-spam-report=spam-report
#export.jobTypeNameMapper.1=nda-bot-report=bot-report


##
# Mail
##

# SMTP hosts
# TODO Change on install
mail.smtpHost.0=smtp01.example.org
mail.smtpHost.1=smtp02.example.org

# Enable debug logging in JavaMail? 
mail.debug=false

# Defult from-address.
# TODO Change on install
mail.fromAddress=Ticket <ticket@example.org>

# Defult to-addresses. Use comma as separator, e.g. "foo@example.org, bar@example.org".
# TODO Change on install
mail.toAddresses=megatron@example.org

# Defult reply to-addresses (optional). Use comma as separator, e.g. "foo@example.org, bar@example.org".
# TODO Change on install
#mail.replyToAddresses=Ticket <ticket@example.org>

# Email addresses to which a copy of every abuse mail is sent to, e.g. "megatron-archive@example.org".
# TODO Change on install
mail.archiveBccAddresses=megatron-archive@example.org

# Email addresses for the mail job summary, e.g. "megatron@example.org".
# TODO Change on install
mail.mailJobSummary.toAddresses=megatron@example.org

# Email addresses for the notification that log job contains high priority entries, e.g. "megatron@example.org".
# TODO Change on install
mail.highPriorityNotification.toAddresses=megatron@example.org

# Use HTML mail? If true, "Content-type" will be set to "text/html". Otherwise is "text/plain" used.
mail.htmlMail=false

# Period in seconds for which an IP is quarantined to avoid that multiple emails are
# sent regarding the same IP number. Set to 0 to turn off quarantine.
mail.ipQuarantinePeriod=345600

# Template for mail subject (default and english).
# TODO Change on install
mail.subjectTemplate=Säkerhetsmeddelande från CERT-SE [CERT-SE #$rtirId]
mail.subjectTemplate.en=Security Notification from CERT-SE [CERT-SE #$rtirId]

# Template for subject in mail job summary mail.
# TODO Change on install
mail.mailJobSummary.subjectTemplate=Megatron: Mail job #$mailJobId finished [CERT-SE #$rtirId]

# Directory for mail templates.
mail.templateDir=/etc/megatron/template/mail

# Default language for mail templates, e.g. "en". 
mail.defaultLanguageCode=sv

# Filename to templates for mail. If property is undefined or empty, the section is skipped.
# The directory is specified in "mail.templateDir".
# Body
#mail.headerFile=
mail.rowFile=debug_row.txt
mail.footerFile=general_footer.txt
# Attachment
mail.attachmentHeaderFile=attachment_header.txt
mail.attachmentRowFile=attachment_row.txt
#mail.attachmentFooterFile=

# Filename for attachment
mail.attachmentName=abuse-report.csv

# Raise error if debug mail templates are used. 
mail.raiseErrorForDebugTemplate=false


##
# RSS
##

# Class name for RSS implementation.
rss.factoryClassName=se.sitic.megatron.rss.rome.RomeRssFactory

# Format for RSS file. The value depends on which RSS class library is used,
# and for Rome the following values are applicable:
#   * Recommended: rss_0.94, rss_1.0, rss_2.0, atom_0.3, atom_1.0
#   * Untested:    rss_0.9, rss_0.91N, rss_0.91U, rss_0.92, rss_0.93 
# ('N' stands for Netscape, and 'U' for Userland.)
rss.format=rss_2.0

# -- Job RSS: Feed for completed log- and mail jobs.

# Is writing to job feed enabled? If false, no file will be created.
rss.job.enabled=true

# Filename for RSS export.
rss.job.file=/var/megatron/tmp/rss/megatron-jobs.xml

# Title of RSS.
rss.job.content.title=Megatron: Completed Log- and Mail Jobs
   
# Url of RSS (will probably be rendered by the RSS reader as a link for the title).
# TODO Change on install
rss.job.content.link=http://www.example.org/

# Description of RSS.
rss.job.content.description=This RSS have been generated by Megatron. 

# Author of RSS.
rss.job.content.author=Megatron

# Copyright of RSS
rss.job.content.copyright=Copyright (c) 2014 

# Max number of items in RSS file? A value of -1 means "no limit".
rss.job.maxNoOfItems=50

# Time in minutes to keep an item in the RSS file. A value of -1 means "keep forever".
rss.job.itemExpireTimeInMinutes=-1

# -- Stats RSS: Statistics generated from the database (--create-rss)
rss.stats.file=/var/megatron/tmp/rss/megatron-stats.xml
rss.stats.content.title=Megatron: Statistics
# TODO Change on install
rss.stats.content.link=http://www.example.org/
rss.stats.content.description=This RSS have been generated by Megatron. 
rss.stats.content.author=Megatron
rss.stats.content.copyright=Copyright (c) 2014
#rss.stats.maxNoOfItems=60
#rss.stats.itemExpireTimeInMinutes=-1


##
# Report
##

# List of report class names. Will be excuted by the "--create-xml" switch.
report.classNames.0=se.sitic.megatron.report.StatisticsXmlReportGenerator
report.classNames.1=se.sitic.megatron.report.GeolocationJsonReportGenerator

# Output directory for report files.
report.outputDir=/var/megatron/tmp/report

# Directory for report templates.
report.templateDir=/etc/megatron/template/report

# -- StatisticsXmlReportGenerator: Creates XML files with overview statistics.
# No. of weeks in the statistics report
report.statistics.noOfWeeks=5

# -- GeolocationJsonReportGenerator: Creates JSON files with geolocation data.
# No. of weeks in the geolocation report (GeolocationJsonReportGenerator)
report.geolocation.noOfWeeks=4

# Generate internal report with e.g. IP addresses? 
report.geolocation.generateInternalReport=false

# Number of entries in the city report 
report.geolocation.noOfEntriesInCityReport=20

# Comma separated list of jobs to exclude (use value in "job_type.name").
report.geolocation.jobTypeKillList=default

# Comma separated list of organization types to exclude (use value in "prio.name").
# TODO Change on install
report.geolocation.organizationTypeKillList=Sitic, CERT-SE

# Converts organization type names (format: from=to)
report.geolocation.organizationTypeNameMapper.0=-=Miscellaneous Organizations

# -- OrganizationReportGenerator: Emails a report to organizations with log entries for a certain period.
# See "report-organization.properties" for more information.
# Include log entries with a create time within the last no. of hours (rounded to even hour)
report.organization.noOfHours=24

# List of job-types to include in the report (use value in "job_type.name").
# Example:
#report.organization.jobTypes.0=shadowserver-drone2
#report.organization.jobTypes.1=shadowserver-sinkhole-http-drone

# Organizations that will receive a report (use value in "organization.id")
# Example
# 1234 ISP 1
#report.organization.recipients.0=1234
# 1235 ISP 2
#report.organization.recipients.1=1235


##
# Filters
##

# Filter can be added before each step in the workflow. Each entry is a list of filters. Example:
# filter.preLineProcessor.classNames.0=se.sitic.megatron.filter.LineNumberFilter
# filter.preStorage.classNames.0=se.sitic.megatron.filter.CountryCodeFilter
# filter.preStorage.classNames.1=se.sitic.megatron.filter.AsnFilter
# filter.preMail.classNames.0=se.sitic.megatron.filter.PriorityFilter
# filter.preDecorator.classNames.0=se.sitic.megatron.filter.OccurrenceFilter
#  
# Two types of filters exists:
#   - ILineFilter: before parsing
#   - ILogEntryFilter: after parsing   

#filter.preLineProcessor.classNames.0=

#filter.preParser.classNames.0=

#filter.preDecorator.classNames.0=

#filter.preStorage.classNames.0=

#filter.preExport.classNames.0=

filter.preMail.classNames.0=se.sitic.megatron.filter.PriorityFilter

# -- RegExpLineFilter: Filter log lines using regular expressions. 
# Note: Only one of the property excludeRegExp or includeRegExp can be defined -- not both.

# Lines that matches this regular expression are filtered out. All other lines are included.
# The following example filters out comments prefixed with "#" or ";": 
#filter.regExpLineFilter.excludeRegExp=^\s*?(#|;)

# Lines that matches this regular expression are included. All other lines are filtered out. 
# The following example includes valid whois lines:
#filter.regExpLineFilter.includeRegExp=^\d+\s+\|

# -- LineNumberFilter: Filter log lines using intervals of line numbers. 
# Note: Only one of the property excludeIntervals or includeIntervals can be defined -- not both.

# Comma-separated list of line number intervals to filter out. 
# The following example filters out the first 10 lines plus lines 80-100:
#filter.lineNumberFilter.excludeIntervals=-10, 80-100

# Comma-separated list of line number intervals to include. 
# The following example includes the first 100 lines (the rest is filtered out):
#filter.lineNumberFilter.includeIntervals=-100

# -- PriorityFilter: Filter log entries using priority in matched organization. 
# Note: Requires that organization matcher have been executed.

# Comma-separated list of priority intervals to include. May be overridden by "--prio". 
# The following line includes log entries with a priority >= 70 (the rest is filtered out):
filter.priorityFilter.includeIntervals=45-

# -- CountryCodeFilter: Filter log entries using the country code and TLD in the hostname.
# Note: Only one of the property excludeCountryCodes or includeCountryCodes can be defined -- not both.

# Comma-separated list of country codes and TLDs to exclude.
# The following example excludes log entries for SE and unknown. All other lines are included.
#filter.countryCodeFilter.excludeCountryCodes=SE, -

# Comma-separated list of country codes and TLDs to include.
# The following example includes log entries for scandinavia and .info (the rest is filtered out):
#filter.countryCodeFilter.includeCountryCodes=SE, FI, NO, DK, info 

# Which organization to filter? Values: "primary", "secondary" (e.g. DDoS victims), or "both".
filter.countryCodeFilter.organizationToFilter=both

# -- AsnFilter: Filter log entries using the AS number.
# Note: Only one of the property excludeAsNumbers or includeAsNumbers can be defined -- not both.

# Comma-separated list of AS numbers to exclude.
# The following example excludes log entries for Bahnhof, Tele 2 and unknown. All other lines are included.
#filter.asnFilter.excludeAsNumbers=8473, 1257, -

# Comma-separated list of AS numbers to include.
# The following example includes log entries for Port 80 (the rest is filtered out):
#filter.asnFilter.includeAsNumbers=39369

# Which organization to filter? Values: "primary", "secondary" (e.g. DDoS victims), or "both".
filter.asnFilter.organizationToFilter=both

# -- OrganizationFilter: Filter out log entries that does not match an organization.

# Match IP-address, hostname, or ASN against the contact database?
# If all three are false, no lookups using OrganizationMatcherDecorator will be done.
# Use this option when OrganizationMatcherDecorator already have been executed.
filter.organizationFilter.matchIpAddress=true
filter.organizationFilter.matchHostname=true
filter.organizationFilter.matchAsn=true

# -- AttributeFilter: Filter log entries by matching an attribute to a regular expression.
# Note: Only one of the property excludeRegExp or includeRegExp can be defined -- not both.

# Attribute (without the "$"-prefix), e.g. "ipAddress", "url", "hostname", "hostname2", "logTimestamp", 
# "organizationName", "originalLogEntry", "additionalItem_httpStatusCode", or "freeText0". 
#filter.attributeFilter.attributeName=url

# Log entries with an attribute value that matches this regular expression are filtered out. All other entries are included.
# The following example filters out ftp URLs (using url): 
#filter.attributeFilter.excludeRegExp=^ftp://

# Log entries with an attribute value that matches this regular expression are included. All other lines are filtered out.
# The following example includes only GET requests (using originalLogEntry): 
#filter.attributeFilter.includeRegExp=\"GET\s

# -- OccurrenceFilter: Filter log entries by occurrence, e.g. "include first 20 matches of the same IP address" or
# "include log entries with more than 10 occurrences of the same URL". 
# Note: Only one of the property excludeIntervals or includeIntervals can be defined -- not both.

# Which attribute to count? Can be a comma separated list of attributes (values are concatenated), but 
# most of the time just one attribute. Remove "$"-prefix from attribute, e.g. "ipAddress", "url", 
# "hostname", "hostname2", "logTimestamp", "organizationName", "originalLogEntry", 
# "additionalItem_httpStatusCode",or "freeText0".
#filter.occurrenceFilter.attributeNames=ipAddress

# Comma-separated list of occurrence intervals to filter out. 
# The following example includes the first 20 lines (the rest is filtered out):
#filter.occurrenceFilter.excludeIntervals=21-

# Comma-separated list of occurrence intervals to include. 
# The following example includes the first 20 lines (the rest is filtered out):
#filter.occurrenceFilter.includeIntervals=-20

# Is input file sorted (e.g. by IP address)?
# If true, only previous line will be kept in memory and matched.
# If false, all attribute values will kept in memory.   
filter.occurrenceFilter.fileSorted=false


##
# File Processor
##

# A file processor handles a whole file, e.g. executes an OS-command to 
# transform the input file. The following file processors are available:
#   - se.sitic.megatron.fileprocessor.OsCommandProcessor
#   - se.sitic.megatron.fileprocessor.DiffProcessor
#   - se.sitic.megatron.fileprocessor.XmlToRowFileProcessor

# List of class names for the file processor. May be undefined. 
#fileProcessor.classNames.0=se.sitic.megatron.fileprocessor.OsCommandProcessor
#fileProcessor.classNames.1=se.sitic.megatron.fileprocessor.DiffProcessor

# Delete temporary files created by a file processor? Default is "true", but
# when debugging it can be handy to keep temporary files.
fileProcessor.deleteTmpFiles=true

# -- OsCommandProcessor: Executes an OS command on the input file. 

# Command to execute in for OsCommandProcessor. Output is then fed into line processor, filters, etc. 
#fileProcessor.osCommandProcessor.command=cat $inputFile

# -- DiffProcessor: Diff current input file with the one in previous run, and filter out old lines.

# Diff command for DiffProcessor, which will filter out old log lines.
# In Windows, diffutils GnuWin32 can be used: from http://gnuwin32.sourceforge.net/packages/diffutils.htm
fileProcessor.diffProcessor.command="C:\Program Files\GnuWin32\bin\diff.exe" $oldFile $newFile
# Unix
#fileProcessor.diffProcessor.command=/usr/bin/diff $oldFile $newFile

# Directory to keep the old files, which will be diffed with the new ones.  
fileProcessor.diffProcessor.oldFilesDir=/var/megatron/tmp/diff-processor-old-files

# Number of backup files to keep of old diff files. 
fileProcessor.diffProcessor.noOfBackupsToKeep=10

# -- XmlToRowFileProcessor: Converts an XML-file using a SAX-parser to a row oriented file.

# Start element of the record. Name of element that contains the elements to save. 
#fileProcessor.xmlToRowFileProcessor.startElement=entry

# Elements to save to the output file. Element values will be written in this order.  
#fileProcessor.xmlToRowFileProcessor.elementsToSave=id, first, last, md5, virusname, url, recent, response, ip, as, review, domain, country, email, inetnum, netname, descr, ns1, ns2

# Separator for values in the output file. Tab="\t".
fileProcessor.xmlToRowFileProcessor.outputSeparator=\t

# -- MultithreadedDnsProcessor: Makes DNS lookups and reverse lookups in several threads 
# to increase performance. Result is used by IpAddressDecorator and HostnameDecorator. 

# Number of threads. Minimum number of DNS requests: noOfThreads * dnsJava.timeOut
fileProcessor.multithreadedDnsProcessor.noOfThreads=100

# Do reverse DNS lookups?
# If true, regExpIp will be used. If false, regExpHostname will be used.
fileProcessor.multithreadedDnsProcessor.reverseDnsLookup=true

# Regular expression to extract IP addresses. May use groups, or not.
fileProcessor.multithreadedDnsProcessor.regExpIp=\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}

# Regular expression to extract hostnames. May use groups, or not.
fileProcessor.multithreadedDnsProcessor.regExpHostname=(?i)https{0,1}://([^\s,]+)


##
# Line Processor
##

# A line processor merges or splits a line.

# Class name for the line processor. May be undefined. 
#lineProcessor.className=se.sitic.megatron.lineprocessor.LineMerger
#lineProcessor.className=se.sitic.megatron.lineprocessor.LineSplitter

# -- LineMerger: Merges lines using reg-exp.

# Merged line: line that matches startRegExp + lines in between + line that matches endRegExp. 
#lineProcessor.merger.startRegExp=
#lineProcessor.merger.endRegExp=

# Restart matching of block if startRegExp matches the last line?
# If false, matching will only restart when endRegExp matches. 
lineProcessor.merger.restartIfStartFound=true

# Separator for appended lines. Space is default if undefined. 
#lineProcessor.merger.separator=

# -- LineSplitter: Splits one line to several lines.
# Note: Only one of the property separatorRegExp or itemRegExp can be defined -- not both.

# One line for each item this regular expression is separating.
#lineProcessor.splitter.separatorRegExp=\t

# One line for each match of this regular expression. 
#lineProcessor.splitter.itemRegExp=.*?\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}

# Append original log row to splitted line?
lineProcessor.splitter.appendOriginalLogRow=false


##
# Decorators
##

# A decorator adds data to a log entry, e.g. country code. 
# The following decorators are available:
#   - se.sitic.megatron.decorator.CombinedDecorator (IP + ASN + Country code + Hostname)
#   - se.sitic.megatron.decorator.CountryCodeDecorator
#   - se.sitic.megatron.decorator.CountryCodeFromHostnameDecorator
#   - se.sitic.megatron.decorator.HostnameDecorator
#   - se.sitic.megatron.decorator.IpAddressDecorator
#   - se.sitic.megatron.decorator.AsnDecorator
#   - se.sitic.megatron.decorator.AsnGeoIpDecorator
#   - se.sitic.megatron.decorator.UrlToHostnameDecorator
#   - se.sitic.megatron.decorator.GeolocationDecorator

# List of class name for decorators to use.
decorator.classNames.0=se.sitic.megatron.decorator.CombinedDecorator

# List of class name for decorators applied before export.
# May be used by a "noisy" decorator, e.g. GeolocationDecorator produces data
# that we do not want to store in the database but we may want it in an export.   
#decorator.preExport.classNames.0=se.sitic.megatron.decorator.GeolocationDecorator

# List of class name for decorators applied before mail.
#decorator.preMail.classNames.0=se.sitic.megatron.decorator.GeolocationDecorator

# -- CombinedDecorator
# List of class name for CombinedDecorator to use.
decorator.combinedDecorator.classNames.0=se.sitic.megatron.decorator.IpAddressDecorator
decorator.combinedDecorator.classNames.1=se.sitic.megatron.decorator.AsnGeoIpDecorator
decorator.combinedDecorator.classNames.2=se.sitic.megatron.decorator.HostnameDecorator
decorator.combinedDecorator.classNames.3=se.sitic.megatron.decorator.CountryCodeFromHostnameDecorator
decorator.combinedDecorator.classNames.4=se.sitic.megatron.decorator.CountryCodeDecorator

# -- OrganizationMatcherDecorator
# Use organization matcher (finds organization for a log entry)? 
decorator.useOrganizationMatcher=true

# Match IP-address, hostname, or ASN against the contact database?
# Match only on ASN if upstream provider should be filtred out, 
# e.g. in the case of a DDoS.
decorator.organizationMatcher.matchIpAddress=true
decorator.organizationMatcher.matchHostname=true
decorator.organizationMatcher.matchAsn=true

# -- CountryCodeFromHostnameDecorator
# List of country codes to handle. If undefined or empty all country codes 
# extracted from the hostname will be assigned to the countryCode-field.
# If this property is set to "SE" and CountryCodeDecorator is used after
# CountryCodeFromHostnameDecorator, then all hostname ending with ".se" *and*
# IP addresses located in Sweden will set the countryCode-field to "SE".      
decorator.countryCodeFromHostnameDecorator.countryCodesToAdd=SE, NU

# -- AsnGeoIpDecorator
# If false, adds "asn" and "asn2" to "additionalItem_asn" and "additionalItem_asn2"
# instead of in LogEntry. Note: AsnDecorator can write to LogEntry and AsnGeoIpDecorator
# can write to both LogEntry and AdditionalItem.
decorator.asnGeoIpDecorator.useAsnInLogEntry=true

# Add AS name to additionalItem?
decorator.asnGeoIpDecorator.addAsName=false

# -- UrlToHostnameDecorator
# Use primary organization and assign the hostname field?
# If false, the hostname2 field will be assigned.  
decorator.urlToHostnameDecorator.usePrimaryOrg=true

# -- GeolocationDecorator
# Fields to add as additional items.
# Possible values: latitude, longitude, city, countryCode, countryName, region, postalCode, areaCode, metroCode
# Suffix with "2" for location of ipAddress2, e.g. "latitude2, longitude2, city2".  
decorator.geolocationDecorator.fieldsToAdd=latitude, longitude, city


##
# Parser
##

# Class name for parser implementation.
parser.className=se.sitic.megatron.parser.RegExpParser

# Maximum ratio of parse errors and total lines in file.
# Example: 0.2 means up to 20% of the lines may have parse errors. 
parser.parseErrorThreshold=0.20

# Maximum number of parse errors. Error raised only if both "parseErrorThreshold" 
# and "maxNoOfParseError" have been passed.   
parser.maxNoOfParseErrors=5

# Date-and time format for the logTimestamp-item. 
# Format reference: http://java.sun.com/j2se/1.5.0/docs/api/java/text/SimpleDateFormat.html
# Additional formats:
#   - epochInSec: Unix epoch in seconds.
#   - epochInMs: Unix epoch in milliseconds.
#   - windowsEpoch: the number of 100-nanoseconds intervals since Jan 1, 1601 UTC. Also
#     called "Windows NT time format", "18-digit Active Directory timestamp", or 
#     "Win32 FILETIME or SYSTEMTIME". Converter: http://www.epochconverter.com/ 
# Example: yyyy-MM-dd HH:mm:ss z --> 2009-07-02 11:39:41 UTC, dd/MMM/yyyy:HH:mm:ss Z --> 07/Jul/2009:11:04:34 +0000
parser.timestampFormat=yyyy-MM-dd HH:mm:ss z

# Prepend the unparsed logTimestamp field with current date (in the format yyyy-MM-dd)?
# Set to true, if the logTimestamp field contain time but not date. 
parser.addCurrentDateToTimestamp=false

# Time-zone to add to parsed time-stamp, e.g. "CET" or "GMT+01:00". 
# Comment out this property if time-zone is specified in the log file, or UTC is implicit used.
# Note: Summer time changes the time-zone. In Sweden, for example, CET (Central European Time) is 
# used in the winter, but CEST (Central European Summer Time) in the summer.
# More info: http://www.timeanddate.com/library/abbreviations/timezones/eu/cet.html
#parser.defaultTimeZone=GMT+01:00

# Check for unused variables in lineRegExp expression?
# Turn off if "$" is used in the regular expression. 
parser.checkUnusedVariables=true

# Remove leading and trailing whitespaces from parsed value.
parser.trimValue=false

# Remove specified enclosing characters from parsed value.
# The following example will remove double quotes from values, e.g. "foobar" --> foobar  
#parser.removeEnclosingCharsFromValue="

# List of attribute value rewriters, e.g. rewrites the url from "http" to "hxxp".
# Attribute values are rewritten just before they are converted to a log entry.    
# 
# Syntax: <attribute name>:<from>--><replace with> 
# Note 1: Spaces are not trimmed (from property value above).
# Note 2: IP addresses, ASNs, and ports can only be converted to an integer 
# value because it's stored in the database as an integer. However, this
# limitation is not present during export (see "export.rewriters").    
#
# See also "export.rewriters" (will not store rewrites to db)
# 
# This example rewrites URLs from "http" to "hxxp":  
#parser.rewriters.0=url:(?i)(h)tt(ps{0,1}://.+)-->$1xx$2

# Remove trailing whitespaces from line before processing it.
parser.removeTrailingSpaces=false

# Expand trailing zero octets in an IP range which is in the format of an 
# IP-address? If true, e.g. "202.131.0.0" will be expanded to "202.131.0.0/16". 
parser.expandIpRangeWithZeroOctets=false

# -- Items, that may be used in parser.lineRegExp and stored in the database.
# An item is specified by a regular expression. 
#
# Note: Java syntax is used in regular expression, which is the same as Perl-syntax
# with a few exceptions. This is described here (search for "Comparison to Perl 5"):   
# http://java.sun.com/j2se/1.5.0/docs/api/java/util/regex/Pattern.html
#
# Tip: Use an interactive regular expression tester and builder: 
#   * QuickREx (Windows): http://www.bastian-bergerhoff.com/eclipse/features/web/QuickREx/standalone.html
#   * Python Regular Expression Builder: http://freshmeat.net/projects/pyreb/
#
# The following embedded flag expressions are common:
#   ?i -- Enables case-insensitive matching.
#   ?s -- Enables dotall mode. In dotall mode, the expression . matches any character, including a line terminator.

# Timestamp in log line. 
# Note: Override this property for more control, e.g. "\d{4}-\d{2}-\d{2} \d{1,2}:\d{2}:\d{2} UTC" 
parser.item.logTimestamp=.*

# Primary host info, e.g. rogue host.
parser.item.ipAddress=\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}|
parser.item.hostname=.*
parser.item.port=\d*
parser.item.asn=\d*
parser.item.countryCode=\w{0,2}

# Secondary host info, e.g. victim.
parser.item.ipAddress2=\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}|
parser.item.hostname2=.*
parser.item.port2=\d*
parser.item.asn2=\d*
parser.item.countryCode2=\w{0,2}

# IP range. Formats: 192.121.218.4, 192.121.218.0/20, 192.121.218.0-255, 192.121.218.0-192.121.220.255, 192.121.x.x 
parser.item.ipRange=\d{1,3}\.(?:\d{1,3}|[xX])\.(?:\d{1,3}|[xX])\.(?:\d{1,3}|[xX])(?:-\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}|-\d{1,3}|/\d{1,2}){0,1}

# URL in log line
parser.item.url=.*

# Free-text. Referenced in lineRegExp as $freeText0, $freeText1, ...  
# Example: parser.item.freeText0=.*
# parser.item.freeText.0=
# parser.item.freeText.1=
# parser.item.freeText.2=
# ...

# Additional untyped name-value items.
# The following example is referenced in lineRegExp as "$additionalItem_ftpUrl": 
#parser.item.additionalItem.ftpUrl=ftp://.*

# Regular expression that matches lines in file. Contains items that are 
# prefixed with "$", e.g. "$ipAddress", "$ipAddress2", "$url", "$freeText0", 
# "$freeText1", "$additionalItem_name", "$additionalItem_anotherName".
# Example: ^$asn\s*\|\s*$ipAddress\s*\|\s*.+\s*\|\s*$countryCode\s*\|\s*.+\s*\|$freeText0$
# parser.lineRegExp=


##
# UI (--ui-org)
##

# Default country code
ui.organizationHandler.defaultCountryCode=SE

# Default language code
ui.organizationHandler.defaultLanguageCode=sv

# Path to export files
ui.organizationHandler.outputDir=/var/megatron/tmp/ui-org

# Organization contact roles e.g Abuse, Technical, Manager.
ui.organizationHandler.validRoles=Abuse, Technical, Administrative, Manager, Unknown

# Timestamp format in UI (exported files uses export.timestampFormat) 
ui.organizationHandler.timestampFormat=yyyy-MM-dd HH:mm:ss


##
# Ticket Handler
##

# Ticket handler class
# ticketHandler.className=se.sitic.megatron.tickethandler.RtTicketHandler

# Ticket handler create ticket parameter names
# These are the key-value pairs to be used in the getNewTicketId call
# ticketHandler.valueKeys=requestors, carbonCopy, subject, parentTicketId

# Create child ticket for each mail
# ticketHandler.createChild=true

# Ticket system sends out mail
# ticketHandler.sendsMail=true

# RT ticket queue name
# ticketHandler.queueName=Megatron

# RT user name
# ticketHandler.user=Megatron

# RT user password
# ticketHandler.password=password

# RT ticket owner 
# ticketHandler.ticketOwner=Megatron

# RT URL
# ticketHandler.url=https://rt.cert.se/rt/REST/1.0/
